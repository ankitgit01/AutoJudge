# ğŸ¯ Coding Problem Difficulty Prediction System

## ğŸ“Œ Project Overview

Competitive programming platforms host thousands of problems whose difficulty levels are often assigned manually. This process is subjective, time-consuming, and inconsistent across platforms.  

This project presents an **end-to-end machine learning system** that automatically:
- **Classifies coding problems** into *Easy, Medium, or Hard*
- **Predicts a numerical difficulty score** for finer-grained assessment

The system uses **classical machine learning**, **feature engineering**, and **ensemble learning**, and is deployed via an interactive **Streamlit web application**.

---

## ğŸ“Š Dataset Used
The dataset provided in the project description is used. Below is the link copy-pasted:
https://github.com/AREEG94FAHAD/TaskComplexityEval-24.git

The dataset consists of programming problems stored in **JSON Lines (`.jsonl`) format**. Each entry includes:

- `title` â€“ Problem title  
- `description` â€“ Full problem statement  
- `input_description` â€“ Input format  
- `output_description` â€“ Output format  
- `sample_io` â€“ Sample input/output  
- `problem_class` â€“ Difficulty label (Easy / Medium / Hard)  
- `problem_score` â€“ Numerical difficulty score  

### Key Characteristics
- Text-heavy dataset
- Class imbalance (Easy problems are more frequent)
- No missing values, but several empty text fields handled during preprocessing

---

## ğŸ§  Approach & Models Used

### 1ï¸âƒ£ Preprocessing & Feature Engineering

- Text cleaning and normalization (LaTeX symbols, numbers, whitespace)
- Constraint extraction from input descriptions (log-scaled)
- Text length as a structural feature
- Keyword-based difficulty indicators (Easy / Medium / Hard signals)
- TF-IDF vectorization (unigrams + bigrams)
- Feature scaling and sparse feature stacking

---

### 2ï¸âƒ£ Classification Models

Multiple classifiers were evaluated:
- Logistic Regression (baseline)
- Random Forest Classifier
- Linear SVM (calibrated)
- Soft Voting Ensemble (LR + RF + SVM)

âœ… **Final Classifier:** Random Forest (best balance of accuracy and robustness)

---

### 3ï¸âƒ£ Regression Models

To predict a continuous difficulty score:

- Random Forest Regressor
- Gradient Boosting Regressor
- Voting Regressor (RF + GB)

#### ğŸš€ Final Regression Model (Stacked)

- Uses **classifier probability outputs as meta-features**
- Ensemble of **XGBoost Regressor + Ridge Regression**
- Significantly improves MAE and RMSE over baseline models

### Note: Separate models are used for classification and regression tasks; therefore, predicted difficulty classes and problem scores may occasionally appear inconsistent.
---

## ğŸ“ˆ Evaluation Metrics

### Classification
- **Accuracy**
- Confusion Matrix
- Precision, Recall, F1-score

### Regression
- **MAE (Mean Absolute Error)**
- **RMSE (Root Mean Squared Error)**
- RÂ² Score

Both models were evaluated on a held-out test set.

---

## ğŸ–¥ï¸ Web Interface

The project includes an interactive **Streamlit web application** that allows users to:

- Input a new coding problem (title, description, input/output)
- View predicted difficulty class (color-coded)
- View predicted numerical difficulty score (out of 10)
- Inspect class probability distribution

The web app strictly reuses the same preprocessing pipeline and trained models to ensure consistency with offline results.

---

## â–¶ï¸ Steps to Run the Project Locally

### 1ï¸âƒ£ Clone the Repository
```bash
git clone <your-github-repo-url>
cd <repo-folder>
```

### 2ï¸âƒ£ Create a Virtual Environment (Recommended)
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install numpy pandas scipy scikit-learn matplotlib joblib xgboost
```

### 4ï¸âƒ£ Run the Streamlit App
*Ensure that the app.py is present directly in the current working directory or use the complete path of app.py*
```bash
python -m streamlit run app.py
```

The application will open in your browser at:
```
http://localhost:8501
```

---

## ğŸ¥ Demo Video

ğŸ“½ï¸ **project demo video Youtube link:**  
https://youtu.be/W6ff9ikGGGo

ğŸ“½ï¸ **Alternative link (Google drive) if the above one doesn't work** 


---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py
â”œâ”€â”€ pickle/
â”‚   â”œâ”€â”€ final_classifier_58.pkl
â”‚   â”œâ”€â”€ final_regressor.pkl
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚   â””â”€â”€ numeric_scaler.pkl
â”œâ”€â”€ preprocessed/
â”‚   â”œâ”€â”€ X_final.npz
â”‚   â”œâ”€â”€ y.csv
â”‚   â””â”€â”€ y_score.csv
â”œâ”€â”€ problems_data.jsonl
â”œâ”€â”€ README.md
```

---

## ğŸ‘¤ Author

**Ankit**  
B.Tech Student  
Interests: Data Science, Machine Learning, Artificial Intelligence

